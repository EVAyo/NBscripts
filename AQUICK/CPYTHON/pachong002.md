## 简单爬虫示例二

### 简例一

`pip install requests`

```python
import requests

url = 'https://www.example.com'
response = requests.get(url)
# 状态码正常
if response.status_code == 200:
    # wb 以二进制写入，以避免出现编码转换错误和数据截断等问题，稳定且通用。
    # 在 with 块中打开的资源会在块结束时自动关闭，无论原始代码是否引发异常。
    with open('example.html', 'wb') as f:
        f.write(response.text)
    print('网页内容已保存到 example.html 文件！')
else:
    print('请求失败。')
```

### 测试获取PDF文件名

方案并不完美。就 core.ac.uk 的文档而言，PASS

`pip install PyPDF`

```
import PyPDF2

# 打开PDF文件
with open('/Users/chanlonhoo/Downloads/41446488.pdf', 'rb') as pdf_file:
    # 创建一个PDF文档读取器对象
    pdf_reader = PyPDF2.PdfReader(pdf_file)

    # 获取第一页的标题
    first_page = pdf_reader.pages[0]
    title = first_page.extract_text()

 # 输出标题
 print(title)
```

### 其他（23.4.23 9:07pm）

打算做个有关于简繁中文及日文筛选，之后看情况进行一次分类。我想中文、日文、英文做个统计，用柱状图或饼图简单分析对比一下。（优先）

竟然无法做到总量统计，那么就找关键词吧：教育、社会、经济、人口

今天对数字区间做个粗略定位，就闲暇时想看相关联的文章，把链接的数字加一或减一就行了。

4144，简中区：

```
- 41441111 电脑信息技术
- 41442077-41443077 材料化工
- 41444001 环境
- 41445011-41446015 教育、应试
- 41447011-41448015 经济
- 41449015 公共服务领域企业分析
```

日文没什么太多规律性，忽略；查看了37980827文献，推测香港也会输出不少英文资料，毕竟曾经香港是英治的，那么台湾的话，很有可能哦。繁中在这个网站上也没太有规律性，不少文献相对较封闭。

本想测试下繁中的，但太过封闭，而且链接多半也不规律，还是批量测一下简中的http status 200吧（靠后）。

### 实际测试过程中（23.4.24 10:13am）

chatgpt回答

```
如果您在代码中使用了正确的选择器，但仍然无法提取所需元素的内容，则可能是由于以下几个原因之一：

1. 该网站可能会拒绝爬虫程序访问其站点。为了防止滥用和保护其网站的稳定性，某些网站可能会限制对其内容的访问。您可以尝试使用代理服务器或更改请求头来规避此问题。
2. 所需元素可能是动态生成的。某些网站使用JavaScript动态生成其内容，这意味着在页面加载后才能够查看和提取它们。在这种情况下，您可以使用Selenium WebDriver等工具来模拟浏览器并等待页面加载后再提取所需数据。
3. 您的选择器可能不正确。请确保您正在使用正确的CSS选择器或XPath表达式来选择所需元素。您可以尝试使用Web开发工具（例如Chrome的开发者工具）来检查页面源代码，并获取所需元素的确切位置和标识符。
4. 您的Python库（如requests和BeautifulSoup）可能已损坏或未正确安装。请确保您已正确安装并使用了最新版本的这些库。
5. 如果您正在使用Windows操作系统，则可能需要在命令提示符窗口中使用chcp命令设置正确的代码页。这可以解决在使用非ASCII字符时出现乱码的问题。

如果您仍然无法解决问题，请提供更多细节，以便我们更好地了解问题所在。
```

接下来考虑webUI自动化的事
